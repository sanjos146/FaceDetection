{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d597a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_path: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\n",
      "Downloading C:\\Users\\SanJos/.insightface\\models\\buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281857/281857 [00:11<00:00, 25538.25KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Found folders: ['noora', 'san']\n",
      "Processing noora...\n",
      "  Encoding img1.jpeg...\n",
      "  Encoding img2.jpeg...\n",
      "  Encoding img3.jpeg...\n",
      "  Encoding img4.jpeg...\n",
      "  Encoding img5.jpeg...\n",
      "  5 images successfully processed for noora\n",
      "Processing san...\n",
      "  Encoding img1.jpeg...\n",
      "  Encoding img2.jpeg...\n",
      "  Encoding img3.jpeg...\n",
      "  Encoding img4.jpeg...\n",
      "  Encoding img5.jpeg...\n",
      "  5 images successfully processed for san\n",
      "Embeddings saved to 'known_faces.pkl'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Path to the main faces folder\n",
    "faces_dir = \"faces/\"\n",
    "\n",
    "# Initialize InsightFace with buffalo_l\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\"])\n",
    "face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Dictionary to hold embeddings\n",
    "known_faces = {}\n",
    "\n",
    "# Ensure the faces directory exists\n",
    "if not os.path.exists(faces_dir):\n",
    "    print(f\"Error: Directory {faces_dir} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found folders: {os.listdir(faces_dir)}\")\n",
    "\n",
    "# Loop through each person folder\n",
    "for person_name in os.listdir(faces_dir):\n",
    "    person_path = os.path.join(faces_dir, person_name)\n",
    "\n",
    "    if not os.path.isdir(person_path):\n",
    "        print(f\"Skipping {person_name} (not a directory)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {person_name}...\")\n",
    "\n",
    "    embeddings = []\n",
    "    img_files = [f for f in os.listdir(person_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:6]  # Max 6 images\n",
    "\n",
    "    if not img_files:\n",
    "        print(f\"  No valid images found for {person_name}\")\n",
    "        continue\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(person_path, img_file)\n",
    "        try:\n",
    "            print(f\"  Encoding {img_file}...\")\n",
    "            # Load and preprocess image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"    Failed to load {img_file}: Unable to read image\")\n",
    "                continue\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            # Generate embedding\n",
    "            faces = face_app.get(img_rgb)\n",
    "            if faces:\n",
    "                embedding = faces[0].embedding  # buffalo_l embeddings are normalized\n",
    "                if embedding.shape == (512,):  # buffalo_l embedding size\n",
    "                    embeddings.append(embedding)\n",
    "                else:\n",
    "                    print(f\"    Invalid embedding shape for {img_file}: {embedding.shape}\")\n",
    "            else:\n",
    "                print(f\"    No faces detected in {img_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Failed to process {img_file}: {e}\")\n",
    "\n",
    "    if embeddings:\n",
    "        print(f\"  {len(embeddings)} images successfully processed for {person_name}\")\n",
    "        # Average embeddings\n",
    "        avg_embedding = np.mean(embeddings, axis=0)\n",
    "        # Normalize the embedding\n",
    "        norm = np.linalg.norm(avg_embedding)\n",
    "        if norm > 0:\n",
    "            avg_embedding = avg_embedding / norm\n",
    "        known_faces[person_name] = avg_embedding\n",
    "    else:\n",
    "        print(f\"  No valid embeddings for {person_name}\")\n",
    "\n",
    "# Save to disk\n",
    "if known_faces:\n",
    "    with open(\"known_faces.pkl\", \"wb\") as f:\n",
    "        pickle.dump(known_faces, f)\n",
    "    print(\"Embeddings saved to 'known_faces.pkl'\")\n",
    "else:\n",
    "    print(\"No embeddings generated. Check images and paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\SanJos/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Session started at 2025-05-02 09:28:30\n",
      "\n",
      "0: 480x640 1 face, 97.7ms\n",
      "Speed: 4.0ms preprocess, 97.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 1, Face face_0 size: (400, 328, 3)\n",
      "Faces detected by InsightFace: 1\n",
      "Distance to noora: 0.9692754745483398\n",
      "Distance to san: 0.2963709831237793\n",
      "\n",
      "0: 480x640 1 face, 81.1ms\n",
      "Speed: 1.8ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 2, Face face_0 size: (443, 363, 3)\n",
      "\n",
      "0: 480x640 1 face, 78.4ms\n",
      "Speed: 3.2ms preprocess, 78.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 3, Face face_0 size: (439, 360, 3)\n",
      "\n",
      "0: 480x640 1 face, 70.3ms\n",
      "Speed: 1.7ms preprocess, 70.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 4, Face face_0 size: (439, 358, 3)\n",
      "\n",
      "0: 480x640 1 face, 71.9ms\n",
      "Speed: 1.9ms preprocess, 71.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 5, Face face_0 size: (440, 359, 3)\n",
      "\n",
      "0: 480x640 1 face, 65.2ms\n",
      "Speed: 1.4ms preprocess, 65.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 6, Face face_0 size: (445, 363, 3)\n",
      "\n",
      "0: 480x640 1 face, 67.8ms\n",
      "Speed: 1.3ms preprocess, 67.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 7, Face face_0 size: (445, 363, 3)\n",
      "\n",
      "0: 480x640 1 face, 72.2ms\n",
      "Speed: 1.4ms preprocess, 72.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 8, Face face_0 size: (448, 365, 3)\n",
      "\n",
      "0: 480x640 1 face, 68.6ms\n",
      "Speed: 2.2ms preprocess, 68.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 9, Face face_0 size: (449, 366, 3)\n",
      "\n",
      "0: 480x640 1 face, 73.3ms\n",
      "Speed: 1.4ms preprocess, 73.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 10, Face face_0 size: (451, 366, 3)\n",
      "Faces detected by InsightFace: 1\n",
      "Distance to noora: 0.9922071099281311\n",
      "Distance to san: 0.2288529872894287\n",
      "\n",
      "0: 480x640 1 face, 106.0ms\n",
      "Speed: 2.5ms preprocess, 106.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 11, Face face_0 size: (454, 371, 3)\n",
      "\n",
      "0: 480x640 1 face, 66.0ms\n",
      "Speed: 1.5ms preprocess, 66.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 12, Face face_0 size: (449, 369, 3)\n",
      "\n",
      "0: 480x640 1 face, 67.5ms\n",
      "Speed: 1.4ms preprocess, 67.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 13, Face face_0 size: (449, 368, 3)\n",
      "\n",
      "0: 480x640 1 face, 75.2ms\n",
      "Speed: 3.5ms preprocess, 75.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 14, Face face_0 size: (449, 368, 3)\n",
      "\n",
      "0: 480x640 1 face, 66.3ms\n",
      "Speed: 1.6ms preprocess, 66.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 15, Face face_0 size: (449, 368, 3)\n",
      "\n",
      "0: 480x640 1 face, 69.0ms\n",
      "Speed: 2.0ms preprocess, 69.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 16, Face face_0 size: (448, 369, 3)\n",
      "\n",
      "0: 480x640 1 face, 69.2ms\n",
      "Speed: 1.3ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 17, Face face_0 size: (449, 369, 3)\n",
      "\n",
      "0: 480x640 1 face, 75.7ms\n",
      "Speed: 1.5ms preprocess, 75.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 18, Face face_0 size: (449, 369, 3)\n",
      "\n",
      "0: 480x640 1 face, 85.4ms\n",
      "Speed: 2.7ms preprocess, 85.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 19, Face face_0 size: (449, 369, 3)\n",
      "\n",
      "0: 480x640 1 face, 73.8ms\n",
      "Speed: 1.7ms preprocess, 73.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 20, Face face_0 size: (449, 369, 3)\n",
      "Faces detected by InsightFace: 1\n",
      "Distance to noora: 1.013758897781372\n",
      "Distance to san: 0.24036073684692383\n",
      "\n",
      "0: 480x640 1 face, 70.7ms\n",
      "Speed: 1.2ms preprocess, 70.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 21, Face face_0 size: (449, 371, 3)\n",
      "\n",
      "0: 480x640 1 face, 68.3ms\n",
      "Speed: 1.5ms preprocess, 68.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 22, Face face_0 size: (448, 371, 3)\n",
      "\n",
      "0: 480x640 1 face, 64.8ms\n",
      "Speed: 1.1ms preprocess, 64.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 23, Face face_0 size: (448, 371, 3)\n",
      "\n",
      "0: 480x640 1 face, 70.2ms\n",
      "Speed: 3.2ms preprocess, 70.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 24, Face face_0 size: (447, 371, 3)\n",
      "\n",
      "0: 480x640 1 face, 64.0ms\n",
      "Speed: 1.3ms preprocess, 64.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 25, Face face_0 size: (444, 367, 3)\n",
      "\n",
      "0: 480x640 1 face, 63.8ms\n",
      "Speed: 1.1ms preprocess, 63.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 26, Face face_0 size: (444, 367, 3)\n",
      "\n",
      "0: 480x640 1 face, 69.6ms\n",
      "Speed: 1.9ms preprocess, 69.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 27, Face face_0 size: (444, 367, 3)\n",
      "\n",
      "0: 480x640 1 face, 65.1ms\n",
      "Speed: 1.8ms preprocess, 65.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 28, Face face_0 size: (445, 368, 3)\n",
      "\n",
      "0: 480x640 1 face, 62.3ms\n",
      "Speed: 1.4ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 29, Face face_0 size: (449, 370, 3)\n",
      "Cache cleared at frame 30\n",
      "\n",
      "0: 480x640 1 face, 71.3ms\n",
      "Speed: 1.3ms preprocess, 71.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 30, Face face_0 size: (445, 368, 3)\n",
      "Faces detected by InsightFace: 1\n",
      "Distance to noora: 0.9880166053771973\n",
      "Distance to san: 0.22491401433944702\n",
      "\n",
      "0: 480x640 1 face, 71.2ms\n",
      "Speed: 2.5ms preprocess, 71.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 31, Face face_0 size: (440, 365, 3)\n",
      "\n",
      "0: 480x640 1 face, 74.2ms\n",
      "Speed: 1.3ms preprocess, 74.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 32, Face face_0 size: (439, 363, 3)\n",
      "\n",
      "0: 480x640 1 face, 67.5ms\n",
      "Speed: 1.4ms preprocess, 67.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 33, Face face_0 size: (434, 357, 3)\n",
      "\n",
      "0: 480x640 1 face, 97.0ms\n",
      "Speed: 2.0ms preprocess, 97.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 34, Face face_0 size: (435, 355, 3)\n",
      "\n",
      "0: 480x640 1 face, 72.9ms\n",
      "Speed: 2.3ms preprocess, 72.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 35, Face face_0 size: (439, 358, 3)\n",
      "\n",
      "0: 480x640 1 face, 67.9ms\n",
      "Speed: 1.3ms preprocess, 67.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 36, Face face_0 size: (445, 358, 3)\n",
      "\n",
      "0: 480x640 1 face, 73.6ms\n",
      "Speed: 1.5ms preprocess, 73.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 37, Face face_0 size: (445, 358, 3)\n",
      "\n",
      "0: 480x640 1 face, 84.2ms\n",
      "Speed: 1.6ms preprocess, 84.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 38, Face face_0 size: (444, 359, 3)\n",
      "\n",
      "0: 480x640 1 face, 67.7ms\n",
      "Speed: 1.9ms preprocess, 67.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 39, Face face_0 size: (444, 359, 3)\n",
      "\n",
      "0: 480x640 1 face, 82.7ms\n",
      "Speed: 1.5ms preprocess, 82.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 40, Face face_0 size: (444, 359, 3)\n",
      "Faces detected by InsightFace: 1\n",
      "Distance to noora: 0.9883629083633423\n",
      "Distance to san: 0.2250078320503235\n",
      "\n",
      "0: 480x640 1 face, 70.6ms\n",
      "Speed: 1.2ms preprocess, 70.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 41, Face face_0 size: (423, 348, 3)\n",
      "\n",
      "0: 480x640 1 face, 75.4ms\n",
      "Speed: 1.2ms preprocess, 75.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 42, Face face_0 size: (423, 348, 3)\n",
      "\n",
      "0: 480x640 1 face, 66.9ms\n",
      "Speed: 1.5ms preprocess, 66.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 43, Face face_0 size: (423, 348, 3)\n",
      "\n",
      "0: 480x640 1 face, 74.9ms\n",
      "Speed: 1.5ms preprocess, 74.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 44, Face face_0 size: (419, 345, 3)\n",
      "\n",
      "0: 480x640 1 face, 72.3ms\n",
      "Speed: 1.4ms preprocess, 72.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 45, Face face_0 size: (429, 349, 3)\n",
      "\n",
      "0: 480x640 1 face, 78.8ms\n",
      "Speed: 1.7ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 46, Face face_0 size: (432, 351, 3)\n",
      "\n",
      "0: 480x640 1 face, 72.7ms\n",
      "Speed: 1.3ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 47, Face face_0 size: (429, 347, 3)\n",
      "\n",
      "0: 480x640 1 face, 75.6ms\n",
      "Speed: 1.4ms preprocess, 75.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 48, Face face_0 size: (429, 347, 3)\n",
      "\n",
      "0: 480x640 1 face, 68.0ms\n",
      "Speed: 1.7ms preprocess, 68.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 49, Face face_0 size: (423, 345, 3)\n",
      "\n",
      "0: 480x640 1 face, 76.9ms\n",
      "Speed: 1.4ms preprocess, 76.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Frame 50, Face face_0 size: (391, 331, 3)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "from scipy.spatial.distance import cosine\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Load known face embeddings\n",
    "with open(\"known_faces.pkl\", \"rb\") as f:\n",
    "    known_faces = pickle.load(f)\n",
    "\n",
    "# Initialize YOLOv8 for face detection\n",
    "yolo_model = YOLO(\"yolov11n-face.pt\")\n",
    "\n",
    "# Initialize InsightFace for face recognition\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\"])\n",
    "face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Parameters\n",
    "threshold = 0.5  # Tuned for buffalo_l cosine distance\n",
    "SKIP_FRAMES = 10  # Faster than DeepFace\n",
    "CACHE_RESET_INTERVAL = 30  # Reset cache every 30 frames\n",
    "frame_count = 0\n",
    "cache = {}\n",
    "timers = {}\n",
    "last_seen = {}\n",
    "session_active = {}\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now()\n",
    "print(f\"Session started at {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Load video file\n",
    "video_path = r\"C:\\Users\\SanJos\\OneDrive\\Desktop\\face_recognition_with_active_window_time\\vid02.mp4\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    display_frame = frame.copy()\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Reset cache periodically\n",
    "    if frame_count % CACHE_RESET_INTERVAL == 0:\n",
    "        cache.clear()\n",
    "        print(f\"Cache cleared at frame {frame_count}\")\n",
    "\n",
    "    # Face detection with YOLOv11\n",
    "    results = yolo_model(frame, imgsz=640, conf=0.5)\n",
    "    faces = results[0].boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
    "    seen_this_frame = set()\n",
    "\n",
    "    for i, (x1, y1, x2, y2) in enumerate(faces):\n",
    "        face_id = f\"face_{i}\"\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "        # Add padding to bounding box (30% of face size)\n",
    "        padding = int(max(x2 - x1, y2 - y1) * 0.3)\n",
    "        x1 = max(x1 - padding, 0)\n",
    "        y1 = max(y1 - padding, 0)\n",
    "        x2 = min(x2 + padding, frame.shape[1])\n",
    "        y2 = min(y2 + padding, frame.shape[0])\n",
    "\n",
    "        face_img = frame[y1:y2, x1:x2]\n",
    "        print(f\"Frame {frame_count}, Face {face_id} size: {face_img.shape}\")\n",
    "\n",
    "        if frame_count % SKIP_FRAMES == 0 or face_id not in cache:\n",
    "            try:\n",
    "                if face_img.shape[0] > 0 and face_img.shape[1] > 0:\n",
    "                    face_img = cv2.resize(face_img, (112, 112))  # Resize for InsightFace\n",
    "                    face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "                    faces_detected = face_app.get(face_img_rgb)\n",
    "                    print(f\"Faces detected by InsightFace: {len(faces_detected)}\")\n",
    "                    if faces_detected:\n",
    "                        embedding = faces_detected[0].embedding  # Normalized\n",
    "                        name = \"Unknown\"\n",
    "                        min_dist = 1.0  # Track lowest distance\n",
    "\n",
    "                        for person, ref_embedding in known_faces.items():\n",
    "                            dist = cosine(embedding, ref_embedding)  # Cosine distance\n",
    "                            print(f\"Distance to {person}: {dist}\")\n",
    "                            if dist < threshold and dist < min_dist:\n",
    "                                name = person\n",
    "                                min_dist = dist\n",
    "                        cache[face_id] = name\n",
    "                    else:\n",
    "                        cache[face_id] = \"Unknown\"\n",
    "                else:\n",
    "                    cache[face_id] = \"Unknown\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing face {face_id}: {e}\")\n",
    "                cache[face_id] = \"Unknown\"\n",
    "\n",
    "        name = cache.get(face_id, \"Detecting...\")\n",
    "        seen_this_frame.add(name)\n",
    "\n",
    "        # Timer update logic\n",
    "        if name != \"Unknown\":\n",
    "            if not session_active.get(name, False):\n",
    "                session_active[name] = True\n",
    "                last_seen[name] = current_time\n",
    "            else:\n",
    "                duration = current_time - last_seen[name]\n",
    "                timers[name] = timers.get(name, 0) + duration\n",
    "                last_seen[name] = current_time\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        # Draw timer (position below if near top)\n",
    "        timer_display = f\"{name}\"\n",
    "        if name in timers:\n",
    "            timer_display += f\" ({int(timers[name])}s)\"\n",
    "        text_y = y1 - 10 if y1 > 30 else y2 + 30  # Move below if near top\n",
    "        cv2.putText(display_frame, timer_display, (x1, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    # Pause timers for absent users\n",
    "    for name in session_active:\n",
    "        if session_active[name] and name not in seen_this_frame:\n",
    "            session_active[name] = False\n",
    "\n",
    "    cv2.imshow(\"Face Recognition with Timer\", display_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f017b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
